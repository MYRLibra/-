{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 书中例题  P63 例4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1:  ['-1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py:532: FutureWarning: Beginning in version 0.22, arrays of bytes/strings will be converted to decimal numbers if dtype='numeric'. It is recommended that you convert the array to a float dtype before using it in scikit-learn, for example by using your_array = your_array.astype(np.float64).\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot perform reduce with flexible type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-9bfe28e8b899>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mclf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mclf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mresult2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'result2: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresult2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[1;32m--> 191\u001b[1;33m                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;31m# boost the variance by epsilon, a small fraction of the standard\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;31m# deviation of the largest dimension.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_smoothing\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_refit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mvar\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m   3365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3366\u001b[0m     return _methods._var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[1;32m-> 3367\u001b[1;33m                          **kwargs)\n\u001b[0m\u001b[0;32m   3368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_var\u001b[1;34m(a, axis, dtype, out, ddof, keepdims)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;31m# Note that if dtype is not of inexact type then arraymean will\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;31m# not be either.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0marrmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         arrmean = um.true_divide(\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot perform reduce with flexible type"
     ]
    }
   ],
   "source": [
    "import naive_bayes as na\n",
    "import numpy as np\n",
    "path=r'E:\\PYproject\\data\\eg4.1.xlsx'\n",
    "data=na.load_excel(path)\n",
    "data=np.array(data)\n",
    "X_data=data[:,:-1]\n",
    "y_data=data[:,-1]\n",
    "x=np.array([2,'S'])\n",
    "\n",
    "#调用自己编写的库\n",
    "clf=na.naiveBayes(lambda_=1)\n",
    "clf.fit(X_data,y_data)\n",
    "result1=clf.predict(x)\n",
    "print('result1: ',result1)\n",
    "\n",
    "#调用sklearn库\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf2=GaussianNB()\n",
    "clf2.fit(X_data,y_data)\n",
    "result2=clf2.predict(x)\n",
    "print('result2: ',result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn库中的朴素贝叶斯算法只能对数值型数据进行处理，不能处理字符型数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1:  [-1]\n",
      "result2:  [-1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.array([[1, 0, -1], [1, 1, -1], [1, 1, 1], [1, 0, 1],\n",
    "                     [1, 0, -1], [2, 0, -1], [2, 1, -1], [2, 1, 1],\n",
    "                     [2, 2, 1], [2, 2, 1], [3, 2, 1], [3, 1, 1],\n",
    "                     [3, 1, 1], [3, 2, 1], [3, 2, -1]])\n",
    "X_data=data[:,:-1]\n",
    "y_data=data[:,-1]\n",
    "x=np.array([2,0])\n",
    "\n",
    "#调用自己编写的库\n",
    "import naive_bayes as na\n",
    "clf1=na.naiveBayes(lambda_=1)\n",
    "clf1.fit(X_data,y_data)\n",
    "result1=clf1.predict(x)\n",
    "print('result1: ',result1)\n",
    "\n",
    "#调用sklearn库\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf2=GaussianNB()\n",
    "clf2.fit(X_data,y_data)\n",
    "result2=clf2.predict(x.reshape(1,-1))\n",
    "print('result2: ',result2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iris数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1:  [0]\n",
      "result2:  [0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris=datasets.load_iris()\n",
    "X_data=iris.data\n",
    "y_data=iris.target\n",
    "x=iris.data[0]\n",
    "#print(iris.feature_names)\n",
    "#print(iris.data)\n",
    "#print(iris.target_names)\n",
    "#print(iris.target)\n",
    "\n",
    "#调用自己编写的库\n",
    "import naive_bayes as na\n",
    "clf1=na.naiveBayes(lambda_=1)\n",
    "clf1.fit(X_data,y_data)\n",
    "result1=clf1.predict(x)\n",
    "print('result1: ',result1)\n",
    "\n",
    "#调用sklearn库\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf2=GaussianNB()\n",
    "clf2.fit(X_data,y_data)\n",
    "result2=clf2.predict(x.reshape(1,-1))\n",
    "print('result2: ',result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result1:  [2, 1, 0, 0, 2, 2, 1, 1, 0, 0, 2, 0, 0, 2, 2, 1, 0, 2, 2, 1, 1, 0, 1, 1, 0, 2, 2, 0, 2, 1, 0, 1, 2, 2, 2, 2, 0, 1, 2, 2, 1, 0, 2, 0, 1]\n",
      "result2:  [2 1 0 0 2 2 1 1 0 0 2 0 0 2 2 1 0 2 2 1 1 0 1 1 0 2 2 0 2 1 0 1 2 2 2 2 0\n",
      " 1 2 2 1 0 2 0 1]\n",
      "accuracy1:  0.9555555555555556\n",
      "accuracy2:  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris=datasets.load_iris()\n",
    "X_data=iris.data\n",
    "y_data=iris.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X_data,y_data,test_size=0.3)#测试集占总数据集的30%\n",
    "\n",
    "\n",
    "#调用自己编写的库\n",
    "import naive_bayes as na\n",
    "clf1=na.naiveBayes(lambda_=1)\n",
    "clf1.fit(X_data,y_data)\n",
    "result1=clf1.predict(X_test)\n",
    "print('result1: ',result1)\n",
    "\n",
    "#调用sklearn库\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf2=GaussianNB()\n",
    "clf2.fit(X_train,y_train)\n",
    "result2=clf2.predict(X_test)\n",
    "print('result2: ',result2)\n",
    "\n",
    "#计算预测准确率\n",
    "count1=0\n",
    "for left,right in zip(result1,y_test):\n",
    "    if left==right:\n",
    "        count1+=1\n",
    "print('accuracy1: ',count1/len(y_test))\n",
    "\n",
    "count2=0\n",
    "for left,right in zip(result2,y_test):\n",
    "    if left==right:\n",
    "        count2+=1\n",
    "print('accuracy2: ',count2/len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips\n",
    "在scikit-learn包中提供了三种常用的朴素贝叶斯算法  \n",
    "上述实验中用的是高斯朴素贝叶斯，主要应用于数值型特征  \n",
    "另外两种为多项式朴素贝叶斯、伯努利朴素贝叶斯，主要应用于文本分类  \n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.naive_bayes import BernoulliNB  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
